{"cells":[{"cell_type":"markdown","metadata":{"id":"Y1cDcKRZwXCL"},"source":["# Key-Value Attention Mechanism Homework on Keras: Character-level Machine Translation (Many-to-Many, encoder-decoder)\n","\n","In this homework, you will create an MT model with key-value attention mechnism that coverts names of constituency MP candidates in the 2019 Thai general election from Thai script to Roman(Latin) script. E.g. นิยม-->niyom "]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6024,"status":"ok","timestamp":1680718678537,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"Oy6QYsP4wa-k","outputId":"8ac7d294-ec86-484c-d1cb-af31f6665b9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.11.0\n"]}],"source":["# !wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import tensorflow as tf\n","print(tf.__version__)\n","\n","import matplotlib as mpl\n","import matplotlib.font_manager as fm\n","\n","fm.fontManager.addfont('thsarabunnew-webfont.ttf') # 3.2+\n","mpl.rc('font', family='TH Sarabun New')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["%matplotlib inline\n","import keras\n","import numpy as np\n","import random\n","np.random.seed(0)\n","\n","from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n","from keras.layers import RepeatVector, Dense, Activation, Lambda\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical, pad_sequences\n","from keras.models import load_model, Model\n","from keras import backend as K\n","\n","# %matplotlib inline\n","# from tensorflow.keras.preprocessing.sequence import pad_sequences\n","# from tensorflow.keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n","# from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n","# from tensorflow.keras.optimizers import Adam\n","# from tensorflow.keras.utils import to_categorical\n","# from tensorflow.keras import Model\n","# from tensorflow.keras.models import load_model\n","# import tensorflow.keras.backend as K\n","# import numpy as np\n","\n","# import random"]},{"cell_type":"markdown","metadata":{"id":"Sq20keO6wXCh"},"source":["## Load Dataset\n","We have generated a toy dataset using names of constituency MP candidates in 2019 Thai General Election from elect.in.th's github(https://github.com/codeforthailand/dataset-election-62-candidates) and tltk (https://pypi.org/project/tltk/) library to convert them into Roman script.\n","\n","<img src=\"https://raw.githubusercontent.com/ekapolc/nlp_2019/master/HW8/images/dataset_diagram.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":78675,"status":"ok","timestamp":1680719078872,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"B8ILK0shprTa","outputId":"55715c6f-dfe1-4bf5-ad12-a021e5f8018a"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":769,"status":"ok","timestamp":1680719079637,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"ecQgM1JRp-7B","outputId":"ed45f3dc-5bbd-4b3b-f968-e0cceb92e171"},"outputs":[],"source":["import shutil\n","shutil.copy(\"/content/drive/MyDrive/FRA 501 IntroNLP&DL/Dataset/mp_name_th_en.csv\", \"/content/mp_name_th_en.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rTQk8W4OwXCk"},"outputs":[],"source":["import csv\n","with open('mp_name_th_en.csv') as csvfile:\n","    readCSV = csv.reader(csvfile, delimiter=',')\n","    name_th = []\n","    name_en = []\n","    for row in readCSV:\n","        name_th.append(row[0])\n","        name_en.append(row[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680719134852,"user":{"displayName":"Paisit Khanarsa","userId":"13279666281938719332"},"user_tz":-420},"id":"lVNHVM_FwXCs","outputId":"1b5c8a4d-5d04-4266-e734-5e199bedaf05"},"outputs":[],"source":["for th, en in zip(name_th[:10],name_en[:10]):\n","    print(th,en)"]},{"cell_type":"markdown","metadata":{"id":"heMTiM7qwXC2"},"source":["## Task1: Preprocess dataset for Keras\n","* 2 dictionaries for indexing (1 for input and another for output)\n","* DON'T FORGET TO INCLUDE special token for padding\n","* DON'T FORGET TO INCLUDE special token for the end of word symbol (output)\n","* Be mindful of your pad_sequences \"padding\" hyperparameter. Choose wisely (post-padding vs pre-padding)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_O5YhjntwXC4"},"outputs":[],"source":["#FILL YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"HNqqnkVSwXC-"},"source":["# Attention Mechanism\n","## Task 2: Code your own (key-value) attention mechnism\n","* PLEASE READ: you DO NOT have to follow all the details in (Daniluk, et al. 2017). You just need to create a key-value attention mechanism where the \"key\" part of the mechanism is used for attention score calculation, and the \"value\" part of the mechanism is used to encode information to create a context vector.  \n","* Define global variables\n","* fill code for one_step_attention function\n","* Hint: use keras.layers.Lambda \n","* Hint: you will probably need more hidden dimmensions than what you've seen in the demo\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSdFcuGuwXDB"},"outputs":[],"source":["from tensorflow.keras.activations import softmax\n","from tensorflow.keras.layers import Lambda\n","def softMaxAxis1(x):\n","    return softmax(x,axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BS3Ziti1wXDH"},"outputs":[],"source":["#These are global variables (shared layers)\n","## Fill your code here\n","## you are allowed to use code in the demo as your template. \n","\n","#repeater = ???\n","#concatenator = ???\n","\n","#Key-values (Hint)\n","splitter = Lambda(lambda x:tf.split(x, num_or_size_splits=2,aixs=2)) \n","\n","#fatten_1 = ???\n","#fatten_2 = ???\n","\n","#activator = ???\n","#dotor = ???\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ecNci8x5wXDN"},"outputs":[],"source":["def one_step_attention(a, s_prev):\n","\n","    #Fill code here\n","    #key, value = ???\n","\n","\n","    #concat = ...key...\n","    #context = ...value...\n","\n","    return None # return whatever you need to complete this homework "]},{"cell_type":"markdown","metadata":{"id":"2bgSCY3NwXDU"},"source":["## Task3: Create and train your encoder/decoder model here\n","* HINT: you will probably need more hidden dimmensions than what you've seen in the demo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3CVrgh9nwXDV"},"outputs":[],"source":["#FILL CODE HERE :Hint --> heatmap in CNN + GradCAM\n","\n","# def model(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n","#   ...\n","\n","# def inference_encoder(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n","#    X = ....\n","#    h = ....\n","\n","#    model = Model(inputs=[X],outputs=h)\n","#    return model\n","\n","# def inference_decoder(Tx, Ty, n_h, n_s, vocab_size, machine_vocab_size):\n","#   s0 = ...\n","#   c0 = ...\n","#   h = ...\n","#   context, attention_scores, energies = one_step_attention(h, s)\n","#   ...decoder_LSTM_cell...\n","#   out = output_layer(s)\n","\n","#   model = Model(inputs=[h,s0,c0],outputs=[out,s,c,atten_score,energies])\n","\n","#   return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XptuOQj-wXDb"},"outputs":[],"source":["#FIT YOUR MODEL HERE"]},{"cell_type":"markdown","metadata":{"id":"3C2RET9GwXDh"},"source":["# Thai-Script to Roman-Script Translation\n","* Task 4: Test your model on 5 examples of your choice including your name! \n","* Task 5: Show your visualization of attention scores on one of your example "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gON7T2xVwXDk"},"outputs":[],"source":["#task 4\n","#fill your code here\n"]},{"cell_type":"markdown","metadata":{"id":"r9-mxbsKwXDp"},"source":["### Plot the attention map\n","* If you need to install thai font: sudo apt install xfonts-thai\n","* this is what your visualization might look like:\n","--> https://drive.google.com/file/d/168J5SPSf4NNKj718wWUEDpUbh8QYZKux/view?usp=share_link"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-4lhl4Vsz6Y8"},"outputs":[],"source":["# EXAMPLES = ???\n","# h = inferEncoder_model.predict(EXAMPLES)\n","# s0 = ???\n","# c0 = ???\n","# ...\n","# Ty = 10\n","# for t in range(Ty):\n","#   out,s,c,attention_scores,energies = inferDecoder_model.predict([h,s0,c0])\n","# ...\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRL8hHaLwXDq"},"outputs":[],"source":["#task 5\n","%matplotlib inline\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","plt.rcParams['font.family']='TH Sarabun New'  #you can change to other font that works for you\n","#fill your code here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XT44RFuxqzBM"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
